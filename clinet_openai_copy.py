import asyncio
import os
import json
from openai import AsyncOpenAI
from dotenv import load_dotenv
from mcp.client.session import ClientSession
from mcp.client.streamable_http import streamablehttp_client

load_dotenv()

class MCPAgent:
    def __init__(self, openai_client, mcp_server_url):
        self.openai_client = openai_client
        self.mcp_server_url = mcp_server_url
        self.mcp_session = None
        self.available_tools = []
        
    async def connect_mcp(self):
        """è¿æ¥åˆ° MCP æœåŠ¡å™¨"""
        try:
            self.read_stream, self.write_stream, self.connection = await streamablehttp_client(self.mcp_server_url).__aenter__()
            self.mcp_session = await ClientSession(self.read_stream, self.write_stream).__aenter__()
            await self.mcp_session.initialize()
            
            # è·å–å¯ç”¨å·¥å…·
            tools_response = await self.mcp_session.list_tools()
            self.available_tools = tools_response.tools
            
            print(f"âœ… è¿æ¥åˆ° MCP æœåŠ¡å™¨: {self.mcp_server_url}")
            print(f"ğŸ“‹ å¯ç”¨å·¥å…· ({len(self.available_tools)}):")
            for tool in self.available_tools:
                print(f" â€¢ {tool.name}: {tool.description}")
            
            return True
        except Exception as e:
            print(f"âŒ è¿æ¥ MCP æœåŠ¡å™¨å¤±è´¥: {e}")
            return False
    
    async def call_mcp_tool(self, tool_name, parameters):
        """è°ƒç”¨ MCP å·¥å…·"""
        try:
            result = await self.mcp_session.call_tool(tool_name, parameters)
            if result.content:
                return result.content[0].text
            return "å·¥å…·è°ƒç”¨æˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ"
        except Exception as e:
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def get_openai_tools_schema(self):
        """å°† MCP å·¥å…·è½¬æ¢ä¸º OpenAI å‡½æ•°è°ƒç”¨æ ¼å¼"""
        openai_tools = []
        for tool in self.available_tools:
            # æ„å»º OpenAI å·¥å…·çš„ schema
            tool_schema = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description or f"MCP tool: {tool.name}",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            }
            
            # æ ¹æ®å·¥å…·åç§°æ·»åŠ å‚æ•°å®šä¹‰
            if tool.name == "add":
                tool_schema["function"]["parameters"] = {
                    "type": "object",
                    "properties": {
                        "a": {"type": "integer", "description": "ç¬¬ä¸€ä¸ªæ•°å­—"},
                        "b": {"type": "integer", "description": "ç¬¬äºŒä¸ªæ•°å­—"}
                    },
                    "required": ["a", "b"]
                }
            elif tool.name == "multiply":
                tool_schema["function"]["parameters"] = {
                    "type": "object",
                    "properties": {
                        "a": {"type": "integer", "description": "ç¬¬ä¸€ä¸ªæ•°å­—"},
                        "b": {"type": "integer", "description": "ç¬¬äºŒä¸ªæ•°å­—"}
                    },
                    "required": ["a", "b"]
                }
            
            openai_tools.append(tool_schema)
        
        return openai_tools
    
    async def chat_with_tools(self, user_message):
        """ä½¿ç”¨å·¥å…·è¿›è¡Œå¯¹è¯"""
        messages = [
            {
                "role": "system", 
                "content": "You are a helpful math teacher that can perform calculations. When you need to calculate something, use the available tools. Always show your work and explain the steps."
            },
            {"role": "user", "content": user_message}
        ]
        
        tools = self.get_openai_tools_schema()
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ OpenAI
            response = await self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                tools=tools,
                tool_choice="auto",
                max_tokens=500
            )
            
            response_message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                # æ·»åŠ åŠ©æ‰‹çš„å“åº”åˆ°æ¶ˆæ¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": response_message.content,
                    "tool_calls": [
                        {
                            "id": tool_call.id,
                            "type": tool_call.type,
                            "function": {
                                "name": tool_call.function.name,
                                "arguments": tool_call.function.arguments
                            }
                        } for tool_call in response_message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in response_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name} å‚æ•°: {function_args}")
                    
                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await self.call_mcp_tool(function_name, function_args)
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": str(tool_result)
                    })
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ OpenAI è·å–æœ€ç»ˆç­”æ¡ˆ
                final_response = await self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=messages,
                    max_tokens=300
                )
                
                return final_response.choices[0].message.content
            else:
                return response_message.content
                
        except Exception as e:
            return f"å¯¹è¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.mcp_session:
                await self.mcp_session.__aexit__(None, None, None)
            if hasattr(self, 'connection'):
                await self.connection.__aexit__(None, None, None)
            print("ğŸ§¹ å·²æ¸…ç† MCP è¿æ¥")
        except Exception as e:
            print(f"æ¸…ç†æ—¶å‡ºé”™: {e}")

async def main():
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    openai_client = AsyncOpenAI(
        api_key=os.getenv("OPENAI_API_KEY", "sk-X8hLBoVBgEb7D4EgY5TLSQ475Kre7Duvf1YdoFwtOHv8ZRnI"),
        base_url=os.getenv("OPENAI_BASE_URL", "https://api.chatanywhere.tech/v1")
    )
    
    # åˆ›å»º MCP Agent
    agent = MCPAgent(openai_client, "http://localhost:8000/mcp")
    
    # è¿æ¥åˆ° MCP æœåŠ¡å™¨
    if not await agent.connect_mcp():
        return
    
    try:
        # æµ‹è¯•å¯¹è¯
        print("\nğŸ’¬ å¼€å§‹å¯¹è¯...")
        
        test_questions = [
            "What is 25 plus 17? Use the calculator tool to work this out.",
            "Can you multiply 15 by 8?",
            "What's 100 + 200 + 50?"
        ]
        
        for question in test_questions:
            print(f"\nğŸ‘¤ ç”¨æˆ·: {question}")
            response = await agent.chat_with_tools(question)
            print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
    
    finally:
        await agent.cleanup()

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ MCP Agent...")
    asyncio.run(main())