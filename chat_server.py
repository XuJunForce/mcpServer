import asyncio
import json
import os
from typing import AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from openai import AsyncOpenAI
from dotenv import load_dotenv
from mcp.client.session import ClientSession
from mcp.client.streamable_http import streamablehttp_client
import logging

# å¯¼å…¥ç°æœ‰çš„MCP Agent
from myMcp import MCPAgent

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

app = FastAPI(title="MCPèŠå¤©åŠ©æ‰‹", description="æ”¯æŒå·¥å…·è°ƒç”¨çš„æµå¼èŠå¤©ç•Œé¢")

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    global openai_client
    try:
        openai_client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL")
        )
        logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not os.getenv("OPENAI_API_KEY"):
            logger.warning("âš ï¸  OPENAI_API_KEY æœªè®¾ç½®")
        if not os.getenv("OPENAI_BASE_URL"):
            logger.warning("âš ï¸  OPENAI_BASE_URL æœªè®¾ç½®")
            
        mcp_url = os.getenv("MCP_SERVER_URL")
        if mcp_url:
            logger.info(f"ğŸ”— MCPæœåŠ¡å™¨URL: {mcp_url}")
        else:
            logger.info("â„¹ï¸  æœªé…ç½®MCP_SERVER_URLï¼Œå°†ä½¿ç”¨æ— MCPæ¨¡å¼")
            
    except Exception as e:
        logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        raise e

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    message: str

# å…¨å±€å˜é‡
openai_client = None
mcp_agent = None

async def init_mcp_agent():
    """åˆå§‹åŒ–MCP Agent"""
    global openai_client, mcp_agent
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    openai_client = AsyncOpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url=os.getenv("OPENAI_BASE_URL")
    )
    
    mcp_server_url = os.getenv("MCP_SERVER_URL")
    
    if mcp_server_url:
        try:
            logger.info(f"å°è¯•è¿æ¥åˆ°MCPæœåŠ¡å™¨: {mcp_server_url}")
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿æŒè¿æ¥ï¼Œæ‰€ä»¥ä½¿ç”¨å…¨å±€è¿æ¥
            async with streamablehttp_client(mcp_server_url) as (read_stream, write_stream, _):
                async with ClientSession(read_stream, write_stream) as mcp_session:
                    await mcp_session.initialize()
                    
                    # è·å–å·¥å…·
                    tools_response = await mcp_session.list_tools()
                    available_tools = tools_response.tools
                    
                    logger.info(f"è¿æ¥æˆåŠŸï¼Œå¯ç”¨å·¥å…·æ•°é‡: {len(available_tools)}")
                    
                    # åˆ›å»ºMCP Agent
                    mcp_agent = MCPAgent(openai_client, mcp_session)
                    mcp_agent.available_tools = available_tools
                    
                    return mcp_agent
        except Exception as e:
            logger.error(f"MCPè¿æ¥å¤±è´¥: {e}")
            mcp_agent = MCPAgent(openai_client, None)
    else:
        logger.info("æœªè®¾ç½®MCP_SERVER_URLï¼Œä½¿ç”¨æ— MCPæ¨¡å¼")
        mcp_agent = MCPAgent(openai_client, None)
    
    return mcp_agent

class StreamingChatAgent:
    """æµå¼èŠå¤©ä»£ç†ï¼ŒåŸºäºç°æœ‰çš„MCPAgentè¿›è¡Œæµå¼æ”¹é€ """
    
    def __init__(self, openai_client, mcp_session=None):
        self.openai_client = openai_client
        self.mcp_session = mcp_session
        self.available_tools = []
    
    @property
    def mcp_available(self):
        return self.mcp_session is not None
    
    def get_openai_tools_schema(self):
        """å¤ç”¨MCPAgentçš„å·¥å…·schemaç”Ÿæˆé€»è¾‘"""
        if not self.mcp_available or not self.available_tools:
            return []
            
        try:
            with open("/root/python_learn/mcpServer/schemas.json", "r", encoding="utf-8") as f:
                schema_params = json.load(f)
        except FileNotFoundError:
            schema_params = {}
        
        openai_tools = []
        
        for tool in self.available_tools:
            tool_params = schema_params.get(tool.name, {})
            
            tool_schema = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description or f"MCP tool: {tool.name}",
                    "parameters": tool_params if tool_params else {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            }        
            openai_tools.append(tool_schema)
        
        return openai_tools
    
    async def call_mcp_tool(self, tool_name, parameters):
        """è°ƒç”¨MCPå·¥å…·"""
        if not self.mcp_available or not self.mcp_session:
            raise Exception("MCPæœåŠ¡å™¨ä¸å¯ç”¨")
            
        try:    
            result = await self.mcp_session.call_tool(tool_name, parameters)
            if result.content and len(result.content) > 0:
                return result.content[0].text
            else:
                return "å·¥å…·è°ƒç”¨æˆåŠŸï¼Œä½†æ— è¿”å›ç»“æœ"
        except Exception as e:
            logger.error(f"MCPå·¥å…·è°ƒç”¨å¼‚å¸¸: {e}")
            raise e
    
    async def stream_chat_with_tools(self, user_message: str) -> AsyncGenerator[str, None]:
        """æµå¼èŠå¤©ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨"""
        
        # å‘é€å¼€å§‹ä¿¡å·
        yield json.dumps({
            "type": "start",
            "message": "å¼€å§‹å¤„ç†æ‚¨çš„é—®é¢˜..."
        }, ensure_ascii=False) + "\n"
        
        # æ„å»ºæ¶ˆæ¯
        system_content = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ã€‚"
        if self.mcp_available and self.available_tools:
            system_content += "ä½ æœ‰ä¸€äº›å·¥å…·å¯ä»¥å¸®åŠ©è·å–å®æ—¶ä¿¡æ¯ï¼Œå¦‚å¤©æ°”æŸ¥è¯¢ç­‰ã€‚"
        
        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_message}
        ]
        
        tools = self.get_openai_tools_schema()
        
        try:
            # é¦–æ¬¡è°ƒç”¨OpenAI
            if tools:
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    tools=tools,
                    tool_choice="auto",
                    max_tokens=500
                )
            else:
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    max_tokens=500
                )
            
            response_message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                # å‘é€å·¥å…·è°ƒç”¨ä¿¡æ¯
                yield json.dumps({
                    "type": "tool_calls",
                    "tools": [
                        {
                            "name": tool_call.function.name,
                            "arguments": json.loads(tool_call.function.arguments)
                        }
                        for tool_call in response_message.tool_calls
                    ]
                }, ensure_ascii=False) + "\n"
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
                messages.append({
                    "role": "assistant",
                    "content": response_message.content,
                    "tool_calls": [{
                        "id": tool_call.id,
                        "type": tool_call.type,
                        "function": {
                            "name": tool_call.function.name,
                            "arguments": tool_call.function.arguments
                        }
                    } for tool_call in response_message.tool_calls]
                })
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in response_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    yield json.dumps({
                        "type": "tool_executing",
                        "tool_name": function_name,
                        "message": f"æ­£åœ¨è°ƒç”¨å·¥å…·: {function_name}"
                    }, ensure_ascii=False) + "\n"
                    
                    try:
                        tool_result = await self.call_mcp_tool(function_name, function_args)
                        
                        yield json.dumps({
                            "type": "tool_result",
                            "tool_name": function_name,
                            "result": str(tool_result)
                        }, ensure_ascii=False) + "\n"
                        
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": str(tool_result)
                        })
                    except Exception as e:
                        error_msg = f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}"
                        yield json.dumps({
                            "type": "tool_error",
                            "tool_name": function_name,
                            "error": error_msg
                        }, ensure_ascii=False) + "\n"
                        
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": error_msg
                        })
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨OpenAIï¼Œè·å–æµå¼å“åº”
                yield json.dumps({
                    "type": "generating",
                    "message": "æ­£åœ¨ç”Ÿæˆå›ç­”..."
                }, ensure_ascii=False) + "\n"
                
                final_response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    max_tokens=300,
                    stream=True
                )
                
                # æµå¼è¾“å‡ºæœ€ç»ˆå›ç­”
                async for chunk in final_response:
                    if chunk.choices and len(chunk.choices) > 0 and chunk.choices[0].delta.content:
                        yield json.dumps({
                            "type": "content",
                            "content": chunk.choices[0].delta.content
                        }, ensure_ascii=False) + "\n"
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥æµå¼è¾“å‡º
                yield json.dumps({
                    "type": "generating",
                    "message": "æ­£åœ¨ç”Ÿæˆå›ç­”..."
                }, ensure_ascii=False) + "\n"
                
                # é‡æ–°è°ƒç”¨è·å–æµå¼å“åº”
                if tools:
                    stream_response = await self.openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages,
                        tools=tools,
                        tool_choice="auto",
                        max_tokens=500,
                        stream=True
                    )
                else:
                    stream_response = await self.openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages,
                        max_tokens=500,
                        stream=True
                    )
                
                async for chunk in stream_response:
                    if chunk.choices and len(chunk.choices) > 0 and chunk.choices[0].delta.content:
                        yield json.dumps({
                            "type": "content",
                            "content": chunk.choices[0].delta.content
                        }, ensure_ascii=False) + "\n"
            
            # å‘é€ç»“æŸä¿¡å·
            yield json.dumps({
                "type": "end",
                "message": "å›ç­”å®Œæˆ"
            }, ensure_ascii=False) + "\n"
            
        except Exception as e:
            logger.error(f"æµå¼èŠå¤©å¤„ç†é”™è¯¯: {type(e).__name__}: {str(e)}")
            import traceback
            traceback.print_exc()
            yield json.dumps({
                "type": "error",
                "error": f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"
            }, ensure_ascii=False) + "\n"

# å…¨å±€æµå¼èŠå¤©ä»£ç†
streaming_agent = None

async def get_streaming_agent():
    """è·å–æµå¼èŠå¤©ä»£ç†"""
    global streaming_agent, openai_client
    
    if streaming_agent is None:
        if openai_client is None:
            openai_client = AsyncOpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                base_url=os.getenv("OPENAI_BASE_URL")
            )
        
        mcp_server_url = os.getenv("MCP_SERVER_URL")
        
        if mcp_server_url:
            try:
                # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æ¯æ¬¡éƒ½åˆ›å»ºæ–°è¿æ¥
                # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåº”è¯¥ç»´æŠ¤é•¿è¿æ¥
                streaming_agent = StreamingChatAgent(openai_client, None)
                logger.info("åˆ›å»ºæ— MCPè¿æ¥çš„æµå¼ä»£ç†")
            except Exception as e:
                logger.error(f"åˆ›å»ºæµå¼ä»£ç†å¤±è´¥: {e}")
                streaming_agent = StreamingChatAgent(openai_client, None)
        else:
            streaming_agent = StreamingChatAgent(openai_client, None)
    
    return streaming_agent

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """æµå¼èŠå¤©æ¥å£"""
    try:
        # ç¡®ä¿OpenAIå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
        global openai_client
        if openai_client is None:
            api_key = os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("OPENAI_BASE_URL")
            
            if not api_key:
                raise HTTPException(
                    status_code=500, 
                    detail="OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶é…ç½®"
                )
            if not base_url:
                raise HTTPException(
                    status_code=500, 
                    detail="OPENAI_BASE_URL ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶é…ç½®"
                )
                
            openai_client = AsyncOpenAI(
                api_key=api_key,
                base_url=base_url
            )
            logger.info("OpenAIå®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
        
        # ä¸ºäº†æ”¯æŒMCPè¿æ¥ï¼Œæˆ‘ä»¬éœ€è¦åœ¨æ¯æ¬¡è¯·æ±‚æ—¶åˆ›å»ºæ–°çš„è¿æ¥
        mcp_server_url = os.getenv("MCP_SERVER_URL")
        
        if mcp_server_url:
            try:
                async def generate_with_mcp():
                    async with streamablehttp_client(mcp_server_url) as (read_stream, write_stream, _):
                        async with ClientSession(read_stream, write_stream) as mcp_session:
                            await mcp_session.initialize()
                            
                            # è·å–å·¥å…·
                            tools_response = await mcp_session.list_tools()
                            available_tools = tools_response.tools
                            
                            # åˆ›å»ºæµå¼ä»£ç†
                            agent = StreamingChatAgent(openai_client, mcp_session)
                            agent.available_tools = available_tools
                            
                            # æµå¼ç”Ÿæˆå“åº”
                            async for chunk in agent.stream_chat_with_tools(request.message):
                                yield chunk
                
                return StreamingResponse(
                    generate_with_mcp(),
                    media_type="text/plain",
                    headers={"Cache-Control": "no-cache"}
                )
            except Exception as e:
                logger.error(f"MCPè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨æ— MCPæ¨¡å¼: {e}")
        
        # æ— MCPæ¨¡å¼
        agent = StreamingChatAgent(openai_client, None)
        
        return StreamingResponse(
            agent.stream_chat_with_tools(request.message),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )
        
    except Exception as e:
        logger.error(f"èŠå¤©æµå¤„ç†é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/", response_class=HTMLResponse)
async def get_chat_page():
    """è¿”å›èŠå¤©é¡µé¢"""
    return """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MCPæ™ºèƒ½èŠå¤©åŠ©æ‰‹</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .chat-container {
            width: 90%;
            max-width: 800px;
            height: 90vh;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .chat-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            text-align: center;
            font-size: 1.5rem;
            font-weight: 600;
        }

        .chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
            background: #f8f9fa;
        }

        .message {
            margin-bottom: 15px;
            max-width: 80%;
        }

        .message.user {
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            margin-right: auto;
        }

        .message-content {
            padding: 12px 16px;
            border-radius: 18px;
            display: inline-block;
            max-width: 100%;
            word-wrap: break-word;
        }

        .message.user .message-content {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .message.assistant .message-content {
            background: white;
            color: #333;
            border: 1px solid #e0e0e0;
        }

        .tool-call {
            background: #e3f2fd;
            border: 1px solid #2196f3;
            border-radius: 10px;
            padding: 10px;
            margin: 10px 0;
            font-family: monospace;
            font-size: 0.9rem;
        }

        .tool-call-header {
            font-weight: bold;
            color: #1976d2;
            margin-bottom: 5px;
        }

        .tool-result {
            background: #e8f5e8;
            border: 1px solid #4caf50;
            border-radius: 8px;
            padding: 8px;
            margin: 5px 0;
            font-size: 0.85rem;
        }

        .tool-error {
            background: #ffebee;
            border: 1px solid #f44336;
            border-radius: 8px;
            padding: 8px;
            margin: 5px 0;
            color: #c62828;
            font-size: 0.85rem;
        }

        .status-message {
            background: #fff3e0;
            border: 1px solid #ff9800;
            border-radius: 8px;
            padding: 8px;
            margin: 5px 0;
            color: #f57c00;
            font-size: 0.85rem;
            font-style: italic;
        }

        .chat-input-container {
            padding: 20px;
            background: white;
            border-top: 1px solid #e0e0e0;
            display: flex;
            gap: 10px;
        }

        .chat-input {
            flex: 1;
            padding: 12px 16px;
            border: 2px solid #e0e0e0;
            border-radius: 25px;
            font-size: 1rem;
            outline: none;
            transition: border-color 0.3s;
        }

        .chat-input:focus {
            border-color: #667eea;
        }

        .send-button {
            padding: 12px 24px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-size: 1rem;
            font-weight: 600;
            transition: transform 0.2s;
        }

        .send-button:hover {
            transform: translateY(-1px);
        }

        .send-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .typing-indicator {
            display: flex;
            align-items: center;
            gap: 5px;
            padding: 10px 16px;
            background: white;
            border: 1px solid #e0e0e0;
            border-radius: 18px;
            margin-bottom: 15px;
        }

        .typing-dot {
            width: 8px;
            height: 8px;
            background: #999;
            border-radius: 50%;
            animation: typing 1.4s infinite ease-in-out;
        }

        .typing-dot:nth-child(2) { animation-delay: 0.2s; }
        .typing-dot:nth-child(3) { animation-delay: 0.4s; }

        @keyframes typing {
            0%, 60%, 100% { transform: translateY(0); }
            30% { transform: translateY(-10px); }
        }

        .chat-messages::-webkit-scrollbar {
            width: 6px;
        }

        .chat-messages::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 3px;
        }

        .chat-messages::-webkit-scrollbar-thumb {
            background: #c1c1c1;
            border-radius: 3px;
        }

        .chat-messages::-webkit-scrollbar-thumb:hover {
            background: #a1a1a1;
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="chat-header">
            ğŸ¤– MCPæ™ºèƒ½èŠå¤©åŠ©æ‰‹
        </div>
        
        <div class="chat-messages" id="chatMessages">
            <div class="message assistant">
                <div class="message-content">
                    ä½ å¥½ï¼æˆ‘æ˜¯MCPæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ æŸ¥è¯¢å¤©æ°”ç­‰å®æ—¶ä¿¡æ¯ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
                </div>
            </div>
        </div>
        
        <div class="chat-input-container">
            <input type="text" class="chat-input" id="chatInput" placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..." />
            <button class="send-button" id="sendButton">å‘é€</button>
        </div>
    </div>

    <script>
        const chatMessages = document.getElementById('chatMessages');
        const chatInput = document.getElementById('chatInput');
        const sendButton = document.getElementById('sendButton');
        
        let isGenerating = false;
        let currentAssistantMessage = null;

        function scrollToBottom() {
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function addUserMessage(message) {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message user';
            messageDiv.innerHTML = `<div class="message-content">${escapeHtml(message)}</div>`;
            chatMessages.appendChild(messageDiv);
            scrollToBottom();
        }

        function addAssistantMessage() {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message assistant';
            messageDiv.innerHTML = '<div class="message-content"></div>';
            chatMessages.appendChild(messageDiv);
            currentAssistantMessage = messageDiv.querySelector('.message-content');
            scrollToBottom();
            return currentAssistantMessage;
        }

        function addTypingIndicator() {
            const typingDiv = document.createElement('div');
            typingDiv.className = 'typing-indicator';
            typingDiv.innerHTML = `
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <span>AIæ­£åœ¨æ€è€ƒ...</span>
            `;
            chatMessages.appendChild(typingDiv);
            scrollToBottom();
            return typingDiv;
        }

        function addToolCall(tools) {
            const toolDiv = document.createElement('div');
            toolDiv.className = 'tool-call';
            
            let toolsHtml = '<div class="tool-call-header">ğŸ› ï¸ è°ƒç”¨å·¥å…·:</div>';
            tools.forEach(tool => {
                toolsHtml += `
                    <div><strong>${tool.name}</strong></div>
                    <div>å‚æ•°: ${JSON.stringify(tool.arguments, null, 2)}</div>
                `;
            });
            
            toolDiv.innerHTML = toolsHtml;
            chatMessages.appendChild(toolDiv);
            scrollToBottom();
        }

        function addToolResult(toolName, result) {
            const resultDiv = document.createElement('div');
            resultDiv.className = 'tool-result';
            resultDiv.innerHTML = `<strong>å·¥å…· ${toolName} æ‰§è¡Œç»“æœ:</strong><br/>${escapeHtml(result)}`;
            chatMessages.appendChild(resultDiv);
            scrollToBottom();
        }

        function addToolError(toolName, error) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'tool-error';
            errorDiv.innerHTML = `<strong>å·¥å…· ${toolName} æ‰§è¡Œå¤±è´¥:</strong><br/>${escapeHtml(error)}`;
            chatMessages.appendChild(errorDiv);
            scrollToBottom();
        }

        function addStatusMessage(message) {
            const statusDiv = document.createElement('div');
            statusDiv.className = 'status-message';
            statusDiv.textContent = message;
            chatMessages.appendChild(statusDiv);
            scrollToBottom();
            return statusDiv;
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        async function sendMessage() {
            if (isGenerating) return;
            
            const message = chatInput.value.trim();
            if (!message) return;

            // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            addUserMessage(message);
            chatInput.value = '';
            
            // ç¦ç”¨è¾“å…¥
            isGenerating = true;
            sendButton.disabled = true;
            chatInput.disabled = true;

            // æ·»åŠ æ‰“å­—æŒ‡ç¤ºå™¨
            const typingIndicator = addTypingIndicator();

            try {
                const response = await fetch('/chat/stream', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ message: message })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                // ç§»é™¤æ‰“å­—æŒ‡ç¤ºå™¨
                typingIndicator.remove();

                // åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨
                const assistantContent = addAssistantMessage();

                const reader = response.body.getReader();
                const decoder = new TextDecoder();

                while (true) {
                    const { value, done } = await reader.read();
                    if (done) break;

                    const chunk = decoder.decode(value);
                    const lines = chunk.split('\\n');

                    for (const line of lines) {
                        if (line.trim()) {
                            try {
                                const data = JSON.parse(line);
                                
                                switch (data.type) {
                                    case 'start':
                                        addStatusMessage(data.message);
                                        break;
                                    case 'tool_calls':
                                        addToolCall(data.tools);
                                        break;
                                    case 'tool_executing':
                                        addStatusMessage(data.message);
                                        break;
                                    case 'tool_result':
                                        addToolResult(data.tool_name, data.result);
                                        break;
                                    case 'tool_error':
                                        addToolError(data.tool_name, data.error);
                                        break;
                                    case 'generating':
                                        addStatusMessage(data.message);
                                        break;
                                    case 'content':
                                        assistantContent.textContent += data.content;
                                        scrollToBottom();
                                        break;
                                    case 'end':
                                        // ç§»é™¤æ‰€æœ‰çŠ¶æ€æ¶ˆæ¯
                                        document.querySelectorAll('.status-message').forEach(el => el.remove());
                                        break;
                                    case 'error':
                                        assistantContent.textContent = 'âŒ ' + data.error;
                                        break;
                                }
                            } catch (e) {
                                console.error('è§£æJSONå¤±è´¥:', e, 'åŸå§‹æ•°æ®:', line);
                            }
                        }
                    }
                }

            } catch (error) {
                // ç§»é™¤æ‰“å­—æŒ‡ç¤ºå™¨
                if (typingIndicator && typingIndicator.parentNode) {
                    typingIndicator.remove();
                }
                
                const errorContent = addAssistantMessage();
                errorContent.textContent = `âŒ è¿æ¥é”™è¯¯: ${error.message}`;
            } finally {
                // é‡æ–°å¯ç”¨è¾“å…¥
                isGenerating = false;
                sendButton.disabled = false;
                chatInput.disabled = false;
                chatInput.focus();
            }
        }

        // äº‹ä»¶ç›‘å¬
        sendButton.addEventListener('click', sendMessage);
        chatInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendMessage();
            }
        });

        // é¡µé¢åŠ è½½å®Œæˆåèšç„¦è¾“å…¥æ¡†
        window.addEventListener('load', () => {
            chatInput.focus();
        });
    </script>
</body>
</html>
    """

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    global openai_client
    
    status = {
        "status": "ok",
        "message": "MCPèŠå¤©æœåŠ¡å™¨è¿è¡Œæ­£å¸¸",
        "openai_client": "å·²åˆå§‹åŒ–" if openai_client else "æœªåˆå§‹åŒ–",
        "mcp_server_url": os.getenv("MCP_SERVER_URL", "æœªé…ç½®"),
        "environment": {
            "openai_api_key": "å·²é…ç½®" if os.getenv("OPENAI_API_KEY") else "æœªé…ç½®",
            "openai_base_url": os.getenv("OPENAI_BASE_URL", "æœªé…ç½®")
        }
    }
    
    return status

@app.post("/test")
async def test_simple_chat():
    """ç®€å•çš„æµ‹è¯•æ¥å£ï¼Œä¸ä½¿ç”¨æµå¼å“åº”"""
    try:
        global openai_client
        if openai_client is None:
            openai_client = AsyncOpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                base_url=os.getenv("OPENAI_BASE_URL")
            )
        
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "è¯·ç®€å•å›å¤ï¼šä½ å¥½"}],
            max_tokens=50
        )
        
        return {
            "status": "success",
            "response": response.choices[0].message.content,
            "message": "OpenAIè¿æ¥æ­£å¸¸"
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "message": "OpenAIè¿æ¥å¤±è´¥"
        }

if __name__ == "__main__":
    import uvicorn
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    if openai_client is None:
        openai_client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL")
        )
    
    logger.info("å¯åŠ¨MCPèŠå¤©æœåŠ¡å™¨...")
    logger.info("è®¿é—® http://localhost:8002 å¼€å§‹èŠå¤©")
    
    uvicorn.run(
        "chat_server:app",
        host="0.0.0.0",
        port=8002,
        reload=True,
        log_level="info"
    )
