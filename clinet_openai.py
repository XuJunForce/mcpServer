import asyncio
import os
import json
from openai import AsyncOpenAI
from dotenv import load_dotenv
from mcp.client.session import ClientSession
from mcp.client.streamable_http import streamablehttp_client

load_dotenv()

class MCPAgent:
    def __init__(self, openai_client, mcp_session):
        self.openai_client = openai_client
        self.mcp_session = mcp_session
        self.available_tools = []
    
    async def call_mcp_tool(self, tool_name, parameters):
        """è°ƒç”¨ MCP å·¥å…·"""
        try:
            result = await self.mcp_session.call_tool(tool_name, parameters)
            if result.content:
                return result.content[0].text
            return "å·¥å…·è°ƒç”¨æˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ"
        except Exception as e:
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def get_openai_tools_schema(self):
        """å°† MCP å·¥å…·è½¬æ¢ä¸º OpenAI å‡½æ•°è°ƒç”¨æ ¼å¼"""
        openai_tools = []
        for tool in self.available_tools:
            # æ„å»º OpenAI å·¥å…·çš„ schema
            tool_schema = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description or f"MCP tool: {tool.name}",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            }
            
            # æ ¹æ®å·¥å…·åç§°æ·»åŠ å‚æ•°å®šä¹‰
            if tool.name == "add":
                tool_schema["function"]["parameters"] = {
                    "type": "object",
                    "properties": {
                        "a": {"type": "integer", "description": "ç¬¬ä¸€ä¸ªæ•°å­—"},
                        "b": {"type": "integer", "description": "ç¬¬äºŒä¸ªæ•°å­—"}
                    },
                    "required": ["a", "b"]
                }
            elif tool.name == "multiply":
                tool_schema["function"]["parameters"] = {
                    "type": "object",
                    "properties": {
                        "a": {"type": "integer", "description": "ç¬¬ä¸€ä¸ªæ•°å­—"},
                        "b": {"type": "integer", "description": "ç¬¬äºŒä¸ªæ•°å­—"}
                    },
                    "required": ["a", "b"]
                }
            
            openai_tools.append(tool_schema)
        
        return openai_tools
    
    async def chat_with_tools(self, user_message):
        """ä½¿ç”¨å·¥å…·è¿›è¡Œå¯¹è¯"""
        messages = [
            {
                "role": "system", 
                "content": "You are a helpful math teacher that can perform calculations. When you need to calculate something, use the available tools. Always show your work and explain the steps."
            },
            {"role": "user", "content": user_message}
        ]
        
        tools = self.get_openai_tools_schema()
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ OpenAI
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                tools=tools,
                tool_choice="auto",
                max_tokens=500
            )
            
            response_message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                # print("å·¥å…·é€‰æ‹©å›ç­”:",response_message.content)
                # print("tool_calls:",response_message.tool_calls)
                # æ·»åŠ åŠ©æ‰‹çš„å“åº”åˆ°æ¶ˆæ¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": response_message.content,
                    "tool_calls": [
                        {
                            "id": tool_call.id,
                            "type": tool_call.type,
                            "function": {
                                "name": tool_call.function.name,
                                "arguments": tool_call.function.arguments
                            }
                        } for tool_call in response_message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in response_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name} å‚æ•°: {function_args}")
                    
                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await self.call_mcp_tool(function_name, function_args)
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": str(tool_result)
                    })
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ OpenAI è·å–æœ€ç»ˆç­”æ¡ˆ
                final_response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    max_tokens=300
                )
                
                return final_response.choices[0].message.content
            else:
                return response_message.content
                
        except Exception as e:
            return f"å¯¹è¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    


async def main():
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    openai_client = AsyncOpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url=os.getenv("OPENAI_BASE_URL")
    )
    
    # ä½¿ç”¨æ­£ç¡®çš„å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¨¡å¼
    mcp_server_url = "http://localhost:8000/mcp"
    
    try:
        # è¿æ¥åˆ° MCP æœåŠ¡å™¨
        async with streamablehttp_client(mcp_server_url) as (read_stream, write_stream, _):
            async with ClientSession(read_stream, write_stream) as mcp_session:
                # åˆå§‹åŒ–è¿æ¥
                await mcp_session.initialize()
                
                # è·å–å¯ç”¨å·¥å…·
                tools_response = await mcp_session.list_tools()
                available_tools = tools_response.tools
                
                print(f"âœ… è¿æ¥åˆ° MCP æœåŠ¡å™¨: {mcp_server_url}")
                print(f"ğŸ“‹ å¯ç”¨å·¥å…· ({len(available_tools)}):")
                for tool in available_tools:
                    print(f" â€¢ {tool.name}: {tool.description}")
                
                # åˆ›å»º MCP Agent
                agent = MCPAgent(openai_client, mcp_session)
                agent.available_tools = available_tools
                
                # æµ‹è¯•å¯¹è¯
                print("\nğŸ’¬ å¼€å§‹å¯¹è¯...")
                
                test_questions = [
                    "What is 25 plus 17? Use the calculator tool to work this out."
                ]
                
                for question in test_questions:
                    print(f"\nğŸ‘¤ ç”¨æˆ·: {question}")
                    response = await agent.chat_with_tools(question)
                    print(f"ğŸ¤– åŠ©æ‰‹: {response}")
                    
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
    
    print("ğŸ§¹ è¿æ¥å·²è‡ªåŠ¨æ¸…ç†")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ MCP Agent...")
    asyncio.run(main())